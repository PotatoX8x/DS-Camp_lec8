{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0329fbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import PorterStemmer\n",
    "from scipy.io import loadmat\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.svm import LinearSVC\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c96dec25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"> Anyone knows how much it costs to host a web portal ?\\n>\\nWell, it depends on how many visitors you're expecting.\\nThis can be anywhere from less than 10 bucks a month to a couple of $100. \\nYou should checkout http://www.rackspace.com/ or perhaps Amazon EC2 \\nif youre running something big..\\n\\nTo unsubscribe yourself from this mailing list, send an email to:\\ngroupname-unsubscribe@egroups.com\\n\\n\""
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd= os.getcwd() # current working directory\n",
    "path = os.path.join(cwd,'data') \n",
    "\n",
    "def get_sample(fn):\n",
    "    with open(fn, 'r') as f:\n",
    "        content = f.read()\n",
    "    return content\n",
    "    \n",
    "fn=  os.path.join(path , 'emailSample1.txt')\n",
    "content = get_sample(fn)\n",
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "062dec77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_tokeniize(content):\n",
    "    '''\n",
    "    content: str - body of mail \n",
    "    return: list of tokens (str) e.g. ['>', 'Anyone', 'knows', 'how', 'much', 'it', 'costs', 'to', 'host', 'a']\n",
    "    '''\n",
    "    tokens = re.split(\"\\s+\", content)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "10c6e71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['>', 'Anyone', 'knows', 'how', 'much', 'it', 'costs', 'to', 'host', 'a', 'web', 'portal', '?', '>', 'Well,', 'it', 'depends', 'on', 'how', 'many', 'visitors', \"you're\", 'expecting.', 'This', 'can', 'be', 'anywhere', 'from', 'less', 'than', '10', 'bucks', 'a', 'month', 'to', 'a', 'couple', 'of', '$100.', 'You', 'should', 'checkout', 'http://www.rackspace.com/', 'or', 'perhaps', 'Amazon', 'EC2', 'if', 'youre', 'running', 'something', 'big..', 'To', 'unsubscribe', 'yourself', 'from', 'this', 'mailing', 'list,', 'send', 'an', 'email', 'to:', 'groupname-unsubscribe@egroups.com', '']\n"
     ]
    }
   ],
   "source": [
    "tokens  = word_tokeniize('''> Anyone knows how much it costs to host a web portal ?\\n>\\nWell, it depends on how many visitors you're expecting.\\nThis can be anywhere from less than 10 bucks a month to a couple of $100. \\nYou should checkout http://www.rackspace.com/ or perhaps Amazon EC2 \\nif youre running something big..\\n\\nTo unsubscribe yourself from this mailing list, send an email to:\\ngroupname-unsubscribe@egroups.com\\n\\n''')\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2e2d1477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_case(tokens):\n",
    "    '''\n",
    "    tokens: ndarry of str\n",
    "    return: ndarry of tokens in lower case (str)\n",
    "    '''\n",
    "    tokens = [x.lower() for x in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2b68e15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['>', 'anyone', 'knows', 'how', 'much', 'it', 'costs', 'to', 'host', 'a', 'web', 'portal', '?', '>', 'well,', 'it', 'depends', 'on', 'how', 'many', 'visitors', \"you're\", 'expecting.', 'this', 'can', 'be', 'anywhere', 'from', 'less', 'than', '10', 'bucks', 'a', 'month', 'to', 'a', 'couple', 'of', '$100.', 'you', 'should', 'checkout', 'http://www.rackspace.com/', 'or', 'perhaps', 'amazon', 'ec2', 'if', 'youre', 'running', 'something', 'big..', 'to', 'unsubscribe', 'yourself', 'from', 'this', 'mailing', 'list,', 'send', 'an', 'email', 'to:', 'groupname-unsubscribe@egroups.com', '']\n"
     ]
    }
   ],
   "source": [
    "tokens = lower_case(tokens)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fa02667b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_tokens (tokens):\n",
    "    '''\n",
    "    tokens: ndarry of str\n",
    "    return: ndarry of tokens replaced with corresponding unified words\n",
    "    '''\n",
    "    tokens = [re.sub(\">\", \"\", x) for x in tokens] # Remove html and other tags\n",
    "    tokens = [re.sub(\"\\d+\", \"number\", x) for x in tokens] # mark all numbers \"number\"\n",
    "    tokens = [re.sub(\"^http.*\", \"httpaddr\", x) for x in tokens] # mark all  urls as \"httpaddr\"\n",
    "    tokens = [re.sub(\".*@.*\", \"emailaddr\", x) for x in tokens] # mark all emails as \"emailaddr\"\n",
    "    tokens = [re.sub(\"\\$\", \"dollar\", x) for x in tokens] # replace $ as \"dollar\"\n",
    "    tokens = [re.sub(\"\\.|,|\\?|!|:|;\", \"\", x) for x in tokens] # get rid of any punctuation\n",
    "    tokens = [re.sub(\"\\W\", \"\", x) for x in tokens] # Remove any non alphanumeric characters\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "35cf02a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'anyone', 'knows', 'how', 'much', 'it', 'costs', 'to', 'host', 'a', 'web', 'portal', '', '', 'well', 'it', 'depends', 'on', 'how', 'many', 'visitors', 'youre', 'expecting', 'this', 'can', 'be', 'anywhere', 'from', 'less', 'than', 'number', 'bucks', 'a', 'month', 'to', 'a', 'couple', 'of', 'dollarnumber', 'you', 'should', 'checkout', 'httpaddr', 'or', 'perhaps', 'amazon', 'ecnumber', 'if', 'youre', 'running', 'something', 'big', 'to', 'unsubscribe', 'yourself', 'from', 'this', 'mailing', 'list', 'send', 'an', 'email', 'to', 'emailaddr', '']\n"
     ]
    }
   ],
   "source": [
    "tokens = normalize_tokens(tokens)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "74401af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_short_tokens (tokens):\n",
    "    '''\n",
    "    tokens: ndarry of str\n",
    "    return: ndarry of filtered tokens (str)\n",
    "    '''\n",
    "    original_tokens_len = len(tokens)\n",
    "    while(\"\" in tokens):\n",
    "        tokens.remove(\"\")\n",
    "    print ('Original len= {}\\nRemaining len= {}'.format(original_tokens_len, len(tokens)))    \n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "461f58e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original len= 65\n",
      "Remaining len= 61\n",
      "['anyone', 'knows', 'how', 'much', 'it', 'costs', 'to', 'host', 'a', 'web', 'portal', 'well', 'it', 'depends', 'on', 'how', 'many', 'visitors', 'youre', 'expecting', 'this', 'can', 'be', 'anywhere', 'from', 'less', 'than', 'number', 'bucks', 'a', 'month', 'to', 'a', 'couple', 'of', 'dollarnumber', 'you', 'should', 'checkout', 'httpaddr', 'or', 'perhaps', 'amazon', 'ecnumber', 'if', 'youre', 'running', 'something', 'big', 'to', 'unsubscribe', 'yourself', 'from', 'this', 'mailing', 'list', 'send', 'an', 'email', 'to', 'emailaddr']\n"
     ]
    }
   ],
   "source": [
    "tokens = filter_short_tokens(tokens)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e32a1253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_tokens(tokens):\n",
    "    '''\n",
    "    tokens: ndarry of str\n",
    "    return: ndarry of stemmed tokens e.g. array(['anyon', 'know', 'how', 'much', 'it', 'cost', 'to', 'host', 'a',\n",
    "       'web', 'portal', 'well', 'it', 'depend', 'on', 'how', 'mani']...\n",
    "    '''\n",
    "    tokens = [ps.stem(w) for w in tokens] \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5385079e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anyon', 'know', 'how', 'much', 'it', 'cost', 'to', 'host', 'a', 'web', 'portal', 'well', 'it', 'depend', 'on', 'how', 'mani', 'visitor', 'your', 'expect', 'thi', 'can', 'be', 'anywher', 'from', 'less', 'than', 'number', 'buck', 'a', 'month', 'to', 'a', 'coupl', 'of', 'dollarnumb', 'you', 'should', 'checkout', 'httpaddr', 'or', 'perhap', 'amazon', 'ecnumb', 'if', 'your', 'run', 'someth', 'big', 'to', 'unsubscrib', 'yourself', 'from', 'thi', 'mail', 'list', 'send', 'an', 'email', 'to', 'emailaddr']\n"
     ]
    }
   ],
   "source": [
    "tokens = stem_tokens(tokens)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d211dd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vocab)= 1,899\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['aa', 'ab', 'abil', ..., 'zdnet', 'zero', 'zip'], dtype=object)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_vocabulary(fn):\n",
    "    '''\n",
    "    fn: str - full path to file \n",
    "    return: ndarray of str e.g. array(['aa', 'ab', 'abil', ..., 'zdnet', 'zero', 'zip'], dtype=object)\n",
    "    '''\n",
    "    vocab_list = pd.read_table(fn, header=None)\n",
    "    vocab = np.array(vocab_list)[:,1] # first columns is index, select only words column  \n",
    "    print ('len(vocab)= {:,}'.format(len(vocab)))\n",
    "    return vocab\n",
    "\n",
    "fn=  os.path.join(path , 'vocab.txt')\n",
    "vocab = get_vocabulary(fn)\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d12da80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def represent_features(tokens, vocab):\n",
    "    '''\n",
    "    tokens: ndarry of str\n",
    "    return: ndarry of binary values 1 if word from vocabulary is in mail 0 otherwise\n",
    "    '''\n",
    "    # YOUR_CODE. Compute the array with 1/0 corresponding to is word from vocabulary in mail \n",
    "    # START_CODE \n",
    "    tokens_represented = [int(i in tokens) for i in vocab]\n",
    "    # END_CODE     \n",
    "\n",
    "    print ('{} word(s) from vocab are in the tokens.'.format(np.sum(tokens_represented)))\n",
    "\n",
    "    return tokens_represented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "aea104b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 word(s) from vocab are in the tokens.\n",
      "[0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "tokens_represented = represent_features(tokens, vocab)\n",
    "print(tokens_represented[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "885cc2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess (content, vocab):\n",
    "    '''\n",
    "    content: str - body of mail \n",
    "    vocab: ndarray of str - list of considered words \n",
    "    '''\n",
    "    # YOUR_CODE. Compute the array with 1/0 corresponding to is word from vocabulary in mail \n",
    "    # START_CODE \n",
    "\n",
    "    # tokenize content    \n",
    "    tokens  = word_tokeniize(content)\n",
    "    \n",
    "    # make lower case\n",
    "    tokens = lower_case(tokens)\n",
    "\n",
    "    # normalize tokens\n",
    "    tokens = normalize_tokens(tokens)\n",
    "\n",
    "    # remove zero words\n",
    "    tokens = filter_short_tokens(tokens)\n",
    "    \n",
    "    # stem words\n",
    "    tokens = stem_tokens(tokens)\n",
    "    \n",
    "    # convert to binary array of features  \n",
    "    tokens_represented = represent_features(tokens, vocab)\n",
    "    tokens_represented = np.array(tokens_represented)\n",
    "    tokens_represented = tokens_represented.reshape(1, -1)\n",
    "    # END_CODE     \n",
    "    \n",
    "    return tokens_represented\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cdd31cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original len= 65\n",
      "Remaining len= 61\n",
      "44 word(s) from vocab are in the tokens.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(content, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6207844f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape= {} (4000, 1899)\n",
      "y_train.shape= {} (4000,)\n",
      "X_test.shape= {} (1000, 1899)\n",
      "y_test.shape= {} (1000,)\n",
      "Sample with index  =0: \n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "fn=  os.path.join(path , 'spamTrain.mat')\n",
    "\n",
    "mat= loadmat(fn)\n",
    "X_train= mat['X']\n",
    "y_train= mat['y'].ravel()\n",
    "\n",
    "print ('X_train.shape= {}',X_train.shape)\n",
    "print ('y_train.shape= {}',y_train.shape)\n",
    "\n",
    "fn=  os.path.join(path , 'spamTest.mat')\n",
    "mat= loadmat(fn)\n",
    "X_test = mat['Xtest']\n",
    "y_test = mat['ytest'].ravel() \n",
    "\n",
    "print ('X_test.shape= {}',X_test.shape)\n",
    "print ('y_test.shape= {}',y_test.shape)\n",
    "index = 0 \n",
    "print ('Sample with index  ={}: \\n{}'.format(index, X_train[index]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0b86528f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score train= 0.99975\n",
      "Score test= 0.992\n"
     ]
    }
   ],
   "source": [
    "C = .1\n",
    "clf= LinearSVC(C=C)\n",
    "clf.fit(X_train,y_train)\n",
    "print ('Score train= {}'.format(clf.score(X_train,y_train)))\n",
    "print ('Score test= {}'.format(clf.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "abdb1dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hour' 'wi' 'credit' 'dollarnumb' 'send' 'click' 'guarante' 'nbsp'\n",
      " 'numberb' 'remov' 'price' 'basenumb' 'visit' 'our' 'most' 'bodi' 'dollar'\n",
      " 'below' 'will' 'lo']\n"
     ]
    }
   ],
   "source": [
    "#print('clf.intercept_={}'.format(clf.intercept_))\n",
    "#print ('clf.coef_={}'.format(clf.coef_))\n",
    "arr = clf.coef_\n",
    "ind = np.argpartition(arr, -20)[0, -20:]\n",
    "top_spam_contributors = vocab[ind]\n",
    "print(top_spam_contributors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "80dad224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original len= 65\n",
      "Remaining len= 61\n",
      "44 word(s) from vocab are in the tokens.\n",
      "emailSample1.txt is ['Not Spam']\n",
      "\n",
      "Original len= 228\n",
      "Remaining len= 222\n",
      "122 word(s) from vocab are in the tokens.\n",
      "emailSample2.txt is ['Not Spam']\n",
      "\n",
      "Original len= 99\n",
      "Remaining len= 97\n",
      "46 word(s) from vocab are in the tokens.\n",
      "spamSample1.txt is ['Spam']\n",
      "\n",
      "Original len= 35\n",
      "Remaining len= 31\n",
      "18 word(s) from vocab are in the tokens.\n",
      "spamSample2.txt is ['Spam']\n",
      "\n",
      "Latter sample:\n",
      "==================================================\n",
      "Best Buy Viagra Generic Online\n",
      "\n",
      "Viagra 100mg x 60 Pills $125, Free Pills & Reorder Discount, Top Selling 100% Quality & Satisfaction guaranteed!\n",
      "\n",
      "We accept VISA, Master & E-Check Payments, 90000+ Satisfied Customers!\n",
      "http://medphysitcstech.ru\n",
      "\n",
      "\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "for sfn in [ 'emailSample1.txt', 'emailSample2.txt', 'spamSample1.txt', 'spamSample2.txt']:\n",
    "    fn = os.path.join(path,sfn)    \n",
    "    content = get_sample(fn)\n",
    "    email = preprocess(content, vocab)\n",
    "    prediction = clf.predict(email)\n",
    "    \n",
    "    label = np.array(['Not Spam','Spam'])\n",
    "    print (f'{sfn} is {label[prediction]}\\n')\n",
    "    #print ('{} is {}\\n'.format(sfn, ('Not Spam','Spam')[prediction])) not working\n",
    "\n",
    "print ('Latter sample:\\n{1}\\n{0}\\n{1}'.format(content, '='*50))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
